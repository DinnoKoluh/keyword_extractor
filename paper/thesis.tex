\documentclass[12pt]{article}
\usepackage[utf8]{inputenc} %mogu sa ovim pisati ščđžć
\usepackage{extsizes} %mogu koristi visinu fonta koju želim 	%

%\usepackage{hyperref} 					
\usepackage{hhline}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{listings}
%\usepackage{xcolor}
\lstset { %
	language=C++,breaklines=true,showstringspaces=false,
	backgroundcolor=\color{black!5}, % set backgroundcolor
	keywordstyle=\color{red},
	commentstyle=\color{blue},
	basicstyle=\sffamily,% basic font setting
	numbers=left,%
	numberstyle={\tiny \color{black}},% size of the numbers
	numbersep=9pt, % this defines how far the numbers are from the text
}

\usepackage{times}

\usepackage{geometry} %štimanje margina
\geometry{textwidth=18cm}
\geometry{textheight=22cm}

\usepackage[english]{babel}

\usepackage{array} %za tabele
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}


\usepackage{enumitem}

\usepackage{caption}
\usepackage{subcaption}

\usepackage{multicol} % multikolone
\usepackage{graphicx}
\usepackage{setspace}

\usepackage[obeyspaces]{url} % for adding paths to a folder
\graphicspath{{./Figures/}}

%\path{{./Data/}} % adddig a path to a folder

\usepackage{wrapfig} %wraps figure
\usepackage{lipsum}  %fills text around figure

\usepackage{bm}  %mogu pisati boldirane formule sa simbolima

\usepackage{amssymb} % za pisannje skupova

\usepackage[usestackEOL]{stackengine} %za piasanje front page-a
\numberwithin{equation}{section}

%\makeatletter
%\renewcommand{\@seccntformat}[1]{}
%\makeatother  % removes numbers from sections but keeps the references
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{\scriptsize \hspace*{0cm}  Thesis topic: Graph-Based Keyword Extraction from
 \\ Scientific Paper Abstracts using Word Embeddings \\ Author: Dinno Koluh}
\lhead{\scriptsize Alma Mater Studiorum \\ Universit\`a  di Bologna \\ Department of Computer Science and Engineering}
\fancyheadoffset{1cm} % to offset the header by some distance 


\usepackage{epsfig}
\usepackage{multirow}
\usepackage{pdfpages}
\setcounter{MaxMatrixCols}{20} % maksimalan broj kolona na 20
\usepackage{float} % da slike nisu poremećene
\usepackage[figurename=Figure]{caption} % mijenja ime sa figure u slika
\usepackage[tablename=Table]{caption} % mijenja ime sa figure u slika

\usepackage{chngcntr}
%\counterwithout{figure}{chapter} % stavlja bojeve unutar captiona slike

\usepackage{colortbl} % color in tables

\addto\captionsenglish{% Replace "english" with the language you use
	\renewcommand{\contentsname}% Promjena naziva content
	{Content}%
}

\usepackage{etoolbox}
%\patchcmd{\thebibliography}{\section*{\refname}}{}{}{} % smakinje ime references

%\usepackage[colorlinks=true, linkcolor = cyan]{hyperref}
\usepackage{hyperref}

%rotating picture
\usepackage{lscape}
\usepackage{rotating}

% tilda
\usepackage{undertilde}

%%coloring links
%\usepackage{hyperref}
%\hypersetup{
	%	colorlinks = true,
	%	linkbordercolor = [white],
	%	linkcolor = [magenta]
	%}

%\usepackage[colorlinks]{hyperref}
%\hypersetup{colorlinks=true, linkcolor=cyan,linkbordercolor=red}

%matlab
\usepackage{listings}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}


\lstset{
	language=Matlab,
	basicstyle=\footnotesize\ttfamily,
	breaklines=true,%
	morekeywords={matlab2tikz},
	keywordstyle=\color{blue},%
	morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},
	identifierstyle=\color{black},%
	stringstyle=\color{mylilas},
	commentstyle=\color{mygreen},%
	showstringspaces=false,%without this there will be a symbol in the places where there is a space
	numbers=left,%
	numberstyle={\tiny \color{black}},% size of the numbers
	numbersep=9pt, % this defines how far the numbers are from the text
	emph=[1]{for,end,break},emphstyle=[1]\color{red}, %some words to emphasise
	emph=[2]{word1,word2}, emphstyle=[2]{style},   
}

\addto\captionsenglish{% Replace "english" with the language you use
	\renewcommand{\contentsname}% Promjena naziva content
	{Contents}%
}

% stil numerisanja stranica
\usepackage{lastpage}
\cfoot{Page \thepage \hspace{1pt} of \pageref{LastPage}}

\usepackage{etoolbox}
\patchcmd{\thebibliography}{\section*{\refname}}{}{}{} % smakne ime references

% za pisanje pseudokoda
\usepackage[plain]{algorithm2e}
%\usepackage{algorithmic}
%\usepackage{algpseudocode}
%\usepackage{algorithmicx}
%\usepackage{algorithm}
%\usepackage{algpseudocode}
%\algnewcommand\algorithmicinput{\textbf{Function:}}
%\algnewcommand\Function{\item[\algorithmicinput]}
%\usepackage{capt-of}
\SetAlgorithmName{Pseudocode}

%\renewcommand{\@algocf@capt@plain}{top}% formerly {bottom}

\makeatletter
\newenvironment{breakablealgorithm}
{% \begin{breakablealgorithm}
		\begin{center}
			\refstepcounter{algorithm}% New algorithm
			\hrule height.8pt depth0pt \kern2pt% \@fs@pre for \@fs@ruled
			\renewcommand{\caption}[2][\relax]{% Make a new \caption
				{\raggedright\textbf{\fname@algorithm~\thealgorithm} ##2\par}%
				\ifx\relax##1\relax % #1 is \relax
				\addcontentsline{loa}{algorithm}{\protect\numberline{\thealgorithm}##2}%
				\else % #1 is not \relax
				\addcontentsline{loa}{algorithm}{\protect\numberline{\thealgorithm}##1}%
				\fi
				\kern2pt\hrule\kern2pt
			}
		}{% \end{breakablealgorithm}
		\kern2pt\hrule\relax% \@fs@post for \@fs@ruled
	\end{center}
}
\makeatother

\makeatletter
\newenvironment{breakalgo}[2][alg:\thealgorithm]{%
	\def\@fs@cfont{\bfseries}%
	\let\@fs@capt\relax%
	\par\noindent%
	\medskip%
	\rule{\linewidth}{.8pt}%
	\vspace{-3pt}%
	\captionof{algorithm}{#2}\label{#1}%
	\vspace{-1.7\baselineskip}%
	\noindent\rule{\linewidth}{.4pt}%
	\vspace{-1.3\baselineskip}%
}{%
	\vspace{-.75\baselineskip}%
	\rule{\linewidth}{.4pt}%
	\medskip%
}
\makeatother


\captionsetup{font=small}
\newcommand*{\matlab}{\textsc{Matlab}}
\newcommand*{\altmatlab}{{\mdseries\matlab}} 

\usepackage{xcolor}

\newsavebox{\bmatrixbox}
\newenvironment{colorbmatrix}
{\begin{lrbox}{\bmatrixbox}
		\mathsurround=0pt
		$\displaystyle
		\begin{bmatrix}}
		{\end{bmatrix}$%
	\end{lrbox}%
	\usebox{\bmatrixbox}%
	\kern-\wd\bmatrixbox
	\makebox[0pt][l]{$\left[\vphantom{\usebox{\bmatrixbox}}\right.$}%
	\kern\wd\bmatrixbox
}

\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}


\begin{document}
	
	\begin{titlepage}
		\begin{center}
			
			{\Large ALMA MATER STUDIORUM \\ UNIVERSIT\`A  DI BOLOGNA \\}
			\vspace{0.4cm} 
			\hrule
			\vspace{0.4cm} 
			{\Large DEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \\} 
			{\Large ARTIFICIAL INTELLIGENCE \\}
			\vspace{0.4cm} 
			\hrule
			\vspace{1cm}
			{\Large MASTER THESIS}\\[0.4cm]
			{\large in} \\[0.4cm]
			{\Large Natural Language Processing}\\[1cm]
			
			\hrule
			\vspace{0.4cm}
			
			{\Huge Graph-Based Keyword Extraction from}\\[0.3cm]
			{\Huge Scientific Paper Abstracts using Word Embeddings}
			\vspace{0.4cm}
			
			\hrule
			\vspace{2cm}
			
			{\large Author:}\\
			{\large Dinno Koluh\\}
			
			\vspace{2cm}
			
			{\large Supervisor:}\\[0.1cm]
			{\large Prof. Paolo Torroni}\\[0.4cm]
			
			{\large Co-Supervisor:}\\[0.1cm]
			{\large Dr. Federico Ruggeri}
			
			\vspace{2cm} 
			{\large Bologna,}\\[0.1cm] 
			{\large October 2023.}
			
		\end{center}
	\end{titlepage}
	\newpage
	\newgeometry{textwidth=16cm, textheight=22cm}
	\thispagestyle{empty}
	
	\begin{spacing}{1.5}
	\section*{Abstract}
	In the era of information overload it became essential to efficiently extract concise, precise and quality information from large texts. One aspect of information extraction is keyword extraction where large texts are represented as sets of tokens and then the most important words i.e. keywords, represent that text. This prospect of keyword extraction is paramount to researchers as they deal with huge numbers of scientific papers, and having a good and concise representation of those papers is essential for them. This thesis paper addresses that problem in the realm of natural language processing (NLP). \\
	Using core concepts of NLP and modeling texts as graphs, in this paper we are going to build a model for the automatic extraction of keywords. This is done in an unsupervised manner as the importance of a word is calculated through the position and weights associated with respective words in the graph. One of the sources of the word weights are word-embeddings as they became a crucial way of representing words as dense vectors. \\
	The results of this paper were compared with keywords that were provided by authors of scientific papers in the area of computer science which act as the ground truth, but crucially are not a component in the model construction, but just serve as a verifier of the model's accuracy.
	
	\textbf{Keywords}: NLP, keyword extraction, scientific papers, graphs, word-embeddings
	
	\newpage
	\pagestyle{empty}
	\tableofcontents
	\setcounter{page}{0}
	\newpage
	%\renewcommand{\listfigurename}{Figures}
	\listoffigures
	\setcounter{page}{0}
	\pagebreak
	
	%\renewcommand{\listtablename}{Popis tabela}
%	\listoftables
%	\thispagestyle{empty}
%	\setcounter{page}{0}
%	\pagebreak
	
	\newpage
	\pagestyle{fancy}
	%\thispagestyle{empty}
	\section{Introduction and Motivation}
	Natural Language Processing (NLP) is a subfield or Artificial Intelligence (AI) and linguistics that has a focus on the interaction between computers and human languages. This is mostly restricted to written language as other fields (like Speech Processing) deal with spoken language (using audio instead of textual features). In the past decade NLP has seen huge attention with the introduction of some key concepts like word-embeddings \cite{we} (which we are going to use) and transformers \cite{transformers}. At the moment of writing of this paper, NLP is the subfield of AI that has the most resources invested into it, mostly in research and development, with new large language models (LLMs) coming out on a daily basis. Our focus will be shifted a bit from Deep Neural Network (DNN) models and more to the traditional Machine Learning (ML) models. \\
	NLP has many subfields and application areas such as:
	\begin{itemize}
		\item Text classification
		\item Information retrieval
		\item Automatic translation
		\item Speech analysis 
		\item Question answering
		\item Conversational agents
		\item Sentiment analysis
	\end{itemize} 
	The field we are going to be working on will be information retrieval, more precisely \textit{keyword extraction}. Keyword (keyphrase) extraction is the automatic selection of important and topical phrases from the body of a document \cite{PeterTurney}. Scientific papers are usually the area where keyword are most frequently used as researchers use them for a quick overview of the paper and also sorting paper into different categories. This is the topic we are going to be working on as well. The keywords are going to be extracted from the abstracts of the scientific papers. One detail we should address that will be important later is the distinction between \textit{keywords} and \textit{keyphrases}. Keywords would be single words or at most MWEs (Multi-Word expressions) while keyphrases are a more complicated entity comprised of several words and they act as a single unit (e.g. the phrase "scientific paper" would be a keyphrase). When doing keyword extraction we might have as an output a combination of both, keywords and keyphrases. Usually keyphrases carry more information than keywords but a combination of both as an output is most representative. From now on, when referring to \textit{keywords} it will also include \textit{keyphrases}, if not explicitly stated otherwise. \\
	The model to be used for keyword extraction is graph-based. The idea is to model words in an abstract as nodes of a graph. Not all the words in the abstract should be included, as keywords are usually composed of a combination of nouns and adjectives (e.g. scientific [ADJ] paper [N]). Then the question comes how to model the edges of the graph? \\
	It starts from the assumption that words that occur in the same context tend to carry a similar meaning. So, the idea is to build a sliding window of some predefined size and words that are in that window are connected with and edge. In that way the final graph carries semantic (the meaning of words) information.
	\section{NLP Pipeline}
	 
	\section{Word Embeddings}
	
	\section{Graph Construction}
	
	\section{Implementation of Keyword Extraction}
	
	\section{Testing, Results and Discussion}
	
	\section{Conclusion}
	
	\newpage
	\section{Literature}
	
	\begin{thebibliography}{8}
		\bibitem{T-RRT} 
		Jaillet, Léonard, Juan Cortés, and Thierry Siméon. "\textit{Transition-based RRT for path planning in continuous cost spaces.}" 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 2008. \\
		\texttt{URL: }\url{https://hal.laas.fr/hal-01986342/document}
		
		\bibitem{RRT}
		LaValle, Steven M. "\textit{Rapidly-exploring random trees: A new tool for path planning}". Computer Science Department, Iowa State University (TR 98–11), October 1998.\\
		\texttt{URL: }\url{http://msl.cs.uiuc.edu/~lavalle/papers/Lav98c.pdf}
		
		\bibitem{PRM}
		Kavraki L. E., Svestka P., Latombe J.C., Overmars M. H. "\textit{Probabilistic roadmaps for path planning in high-dimensional configuration spaces.}". IEEE Transactions on Robotics and Automation, 1996. \\
		\texttt{URL: }\url{http://dspace.library.uu.nl/handle/1874/17328}
		
		\bibitem{BiRRT}
		Kuffner, James J., and Steven M. LaValle. "\textit{RRT-connect: An efficient approach to single-query path planning.}", Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No. 00CH37065). Vol. 2. IEEE, 2000. \\
		\texttt{URL: }\url{http://kuffner.org/james/papers/kuffner_icra2000.pdf}
		
		\bibitem{proteinFolding}
		LaValle, Steven M. "\textit{Planning Algorithms}". Cambridge University Press. ISBN 978-1-139-45517-6, May 2006.
		
		\bibitem{siciliano}
		B. Siciliano, L. Sciavicco, L. Villani, and G. Oriolo. "\textit{Robotics: Modelling, Planning and Control}". Springer, London, UK, 2009.
		
		\bibitem{MonteCarlo}
		Kroese D. P., Brereton T., Taimre T., Botev Z. I. "\textit{Why the Monte Carlo method is so important today}", 2014.
		
		\bibitem{juricGrafovi}
		Jurić Ž. "\textit{Diskretna matematika za studente tehničkih nauka}". ETF Sarajevo, UNSA, 2017. 
		
		\bibitem{convexHullAlgo}
		Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. "\textit{Introduction to Algorithms}", Second Edition. MIT Press and McGraw-Hill. ISBN 0-262-03293-7. \textit{Section 33.3: Finding the convex hull}, pp. 947–957, 2001.
		
		\bibitem{inhull}
		John D'Errico (2020). Efficient test for points inside a convex hull in n dimensions. \\ \textsc{Matlab} Central File Exchange. Retrieved December 11, 2020. \\ \texttt{URL: }\url{https://www.mathworks.com/matlabcentral/fileexchange/10226-inhull}
		
		\bibitem{p_poly_line}
		Michael Yoshpe (2020). Distance from points to polyline or polygon. \\
		\textsc{Matlab} Central File Exchange. Retrieved December 11, 2020. \\ \texttt{URL: }\url{https://www.mathworks.com/matlabcentral/fileexchange/12744-distance-from-points-to-polyline-or-polygon}
		
		\bibitem{vert2lcon}
		Matt J. (2020). Analyze N-dimensional Polyhedra in terms of Vertices or (In)Equalities. \\
		\textsc{Matlab} Central File Exchange. Retrieved December 10, 2020\\
		\texttt{URL: }\url{https://www.mathworks.com/matlabcentral/fileexchange/30892-analyze-n-dimensional-polyhedra-in-terms-of-vertices-or-in-equalities}
		
		\bibitem{lsqlin}
		\texttt{lsqlin} function description. Solve constrained linear least-squares problems. \\
		\texttt{URL: }\url{https://www.mathworks.com/help/optim/ug/lsqlin.html}
	\end{thebibliography}

	\end{spacing}
	
\end{document}