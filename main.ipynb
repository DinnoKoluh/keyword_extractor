{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nlp_utils import *\n",
    "from data_utils import *\n",
    "from KeywordExtractor import *\n",
    "from gensim.models import Word2Vec\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORD EMBEDDINGS\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import gensim.downloader as api\n",
    "# Download a pre-trained Word2Vec model (you can choose other models as well)\n",
    "model_name = \"glove-wiki-gigaword-50\"\n",
    "\n",
    "# Download and load the model (this might take a while to download)\n",
    "# model = api.load(model_name)\n",
    "# model.save('data/model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = load_abstract('ex1')\n",
    "joined, abstracts, titles, keywords = get_data('data/CS_papers.csv', version=\"CS\")\n",
    "abstracts, keywords = get_data('data/inspec_papers.csv', version=\"inspec\")\n",
    "abstract = abstracts[0]\n",
    "#abstract = \"The country of Japan has developed to a great economy after WW1. Japan is a developed island nation. The cats are jumping over the fences.\"\n",
    "#abstract = \"I like deep learning. I like NLP. I enjoy flying. Japan is a developed island nation. I like Japan because it is an island. \"\n",
    "ke = KeywordExtractor(abstract=abstract)\n",
    "print(ke.tokens)\n",
    "print(ke.sentences)\n",
    "print(ke.co)\n",
    "ke.graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import keywords\n",
    "\n",
    "# Extract keywords using TextRank\n",
    "extracted_keywords = keywords(abstract, lemmatize=True)\n",
    "\n",
    "# Print the extracted keywords\n",
    "print(extracted_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pytextrank\n",
    "\n",
    "# example text\n",
    "text = abstract\n",
    "\n",
    "# load a spaCy model, depending on language, scale, etc.\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# add PyTextRank to the spaCy pipeline\n",
    "nlp.add_pipe(\"textrank\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# examine the top-ranked phrases in the document\n",
    "print(f\"Ground truth {keywords[0]}\")\n",
    "for phrase in doc._.phrases:\n",
    "    print(phrase.text)\n",
    "    print(phrase.rank, phrase.count)\n",
    "    print(phrase.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ke.unique_tokens))\n",
    "labels = nx.get_edge_attributes(ke.graph,'weight')\n",
    "print(ke.graph.edges)\n",
    "print(labels)\n",
    "#ke.add_we_weights()\n",
    "ke.order_nodes()\n",
    "ke.visualize_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abstracts[0])\n",
    "print(keywords[0])\n",
    "ke.order_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = KeyedVectors.load('data/model.model')\n",
    "a = get_word_em(\"nlp\")\n",
    "b = get_word_em(\"apple\")\n",
    "print(model.similarity(\"nlp\", \"apple\"))\n",
    "print(cosine_similarity(a.reshape(1, -1), b.reshape(1, -1))[0])\n",
    "similar_words = model.similar_by_vector(a, topn=5)\n",
    "print(\"\\nWords similar to:\")\n",
    "for word, score in similar_words:\n",
    "    print(f\"{word}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load('data/model.model')\n",
    "# Find the vector representation of a word\n",
    "word_vector = model[\"apple\"]\n",
    "print(\"Vector representation of 'apple':\")\n",
    "print(word_vector)\n",
    "\n",
    "# Find similar words\n",
    "similar_words = model.most_similar(\"apple\", topn=5)\n",
    "print(\"\\nWords similar to 'apple':\")\n",
    "for word, score in similar_words:\n",
    "    print(f\"{word}: {score}\")\n",
    "\n",
    "# Perform vector arithmetic (e.g., king - man + woman = queen)\n",
    "result = model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)\n",
    "print(\"\\n'king' - 'man' + 'woman' =\")\n",
    "for word, score in result:\n",
    "    print(f\"{word}: {score}\")\n",
    "\n",
    "# Assuming you have already loaded a pretrained Word2Vec model\n",
    "word1 = \"learning\"\n",
    "word2 = \"island\"\n",
    "\n",
    "# Calculate the similarity between two words\n",
    "similarity_score = model.similarity(word1, word2)\n",
    "\n",
    "print(f\"Similarity between '{word1}' and '{word2}': {similarity_score:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
